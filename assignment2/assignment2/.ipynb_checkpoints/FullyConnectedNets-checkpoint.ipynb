{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fully-Connected Neural Nets\n",
    "In the previous homework you implemented a fully-connected two-layer neural network on CIFAR-10. The implementation was simple but not very modular since the loss and gradient were computed in a single monolithic function. This is manageable for a simple two-layer network, but would become impractical as we move to bigger models. Ideally we want to build networks using a more modular design so that we can implement different layer types in isolation and then snap them together into models with different architectures.\n",
    "\n",
    "In this exercise we will implement fully-connected networks using a more modular approach. For each layer we will implement a `forward` and a `backward` function. The `forward` function will receive inputs, weights, and other parameters and will return both an output and a `cache` object storing data needed for the backward pass, like this:\n",
    "\n",
    "```python\n",
    "def layer_forward(x, w):\n",
    "  \"\"\" Receive inputs x and weights w \"\"\"\n",
    "  # Do some computations ...\n",
    "  z = # ... some intermediate value\n",
    "  # Do some more computations ...\n",
    "  out = # the output\n",
    "   \n",
    "  cache = (x, w, z, out) # Values we need to compute gradients\n",
    "   \n",
    "  return out, cache\n",
    "```\n",
    "\n",
    "The backward pass will receive upstream derivatives and the `cache` object, and will return gradients with respect to the inputs and weights, like this:\n",
    "\n",
    "```python\n",
    "def layer_backward(dout, cache):\n",
    "  \"\"\"\n",
    "  Receive derivative of loss with respect to outputs and cache,\n",
    "  and compute derivative with respect to inputs.\n",
    "  \"\"\"\n",
    "  # Unpack cache values\n",
    "  x, w, z, out = cache\n",
    "  \n",
    "  # Use values in cache to compute derivatives\n",
    "  dx = # Derivative of loss with respect to x\n",
    "  dw = # Derivative of loss with respect to w\n",
    "  \n",
    "  return dx, dw\n",
    "```\n",
    "\n",
    "After implementing a bunch of layers this way, we will be able to easily combine them to build classifiers with different architectures.\n",
    "\n",
    "In addition to implementing fully-connected networks of arbitrary depth, we will also explore different update rules for optimization, and introduce Dropout as a regularizer and Batch Normalization as a tool to more efficiently optimize deep networks.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# As usual, a bit of setup\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cs231n.classifiers.fc_net import *\n",
    "from cs231n.data_utils import get_CIFAR10_data\n",
    "from cs231n.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from cs231n.solver import Solver\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val:  (1000, 3, 32, 32)\n",
      "X_train:  (49000, 3, 32, 32)\n",
      "X_test:  (1000, 3, 32, 32)\n",
      "y_val:  (1000,)\n",
      "y_train:  (49000,)\n",
      "y_test:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the (preprocessed) CIFAR10 data.\n",
    "\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in data.iteritems():\n",
    "  print '%s: ' % k, v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine layer: foward\n",
    "Open the file `cs231n/layers.py` and implement the `affine_forward` function.\n",
    "\n",
    "Once you are done you can test your implementaion by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_forward function:\n",
      "difference:  9.76984772881e-10\n"
     ]
    }
   ],
   "source": [
    "# Test the affine_forward function\n",
    "\n",
    "num_inputs = 2\n",
    "input_shape = (4, 5, 6)\n",
    "output_dim = 3\n",
    "\n",
    "input_size = num_inputs * np.prod(input_shape)\n",
    "weight_size = output_dim * np.prod(input_shape)\n",
    "\n",
    "x = np.linspace(-0.1, 0.5, num=input_size).reshape(num_inputs, *input_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=weight_size).reshape(np.prod(input_shape), output_dim)\n",
    "b = np.linspace(-0.3, 0.1, num=output_dim)\n",
    "\n",
    "out, _ = affine_forward(x, w, b)\n",
    "correct_out = np.array([[ 1.49834967,  1.70660132,  1.91485297],\n",
    "                        [ 3.25553199,  3.5141327,   3.77273342]])\n",
    "\n",
    "# Compare your output with ours. The error should be around 1e-9.\n",
    "print 'Testing affine_forward function:'\n",
    "print 'difference: ', rel_error(out, correct_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine layer: backward\n",
    "Now implement the `affine_backward` function and test your implementation using numeric gradient checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_backward function:\n",
      "dx error:  2.48820268493e-10\n",
      "dw error:  2.60710958043e-10\n",
      "db error:  2.05619321349e-11\n"
     ]
    }
   ],
   "source": [
    "# Test the affine_backward function\n",
    "\n",
    "x = np.random.randn(10, 2, 3)\n",
    "w = np.random.randn(6, 5)\n",
    "b = np.random.randn(5)\n",
    "dout = np.random.randn(10, 5)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: affine_forward(x, w, b)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: affine_forward(x, w, b)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: affine_forward(x, w, b)[0], b, dout)\n",
    "\n",
    "_, cache = affine_forward(x, w, b)\n",
    "dx, dw, db = affine_backward(dout, cache)\n",
    "\n",
    "# The error should be around 1e-10\n",
    "print 'Testing affine_backward function:'\n",
    "print 'dx error: ', rel_error(dx_num, dx)\n",
    "print 'dw error: ', rel_error(dw_num, dw)\n",
    "print 'db error: ', rel_error(db_num, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU layer: forward\n",
    "Implement the forward pass for the ReLU activation function in the `relu_forward` function and test your implementation using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing relu_forward function:\n",
      "difference:  4.99999979802e-08\n"
     ]
    }
   ],
   "source": [
    "# Test the relu_forward function\n",
    "\n",
    "x = np.linspace(-0.5, 0.5, num=12).reshape(3, 4)\n",
    "\n",
    "out, _ = relu_forward(x)\n",
    "correct_out = np.array([[ 0.,          0.,          0.,          0.,        ],\n",
    "                        [ 0.,          0.,          0.04545455,  0.13636364,],\n",
    "                        [ 0.22727273,  0.31818182,  0.40909091,  0.5,       ]])\n",
    "\n",
    "# Compare your output with ours. The error should be around 1e-8\n",
    "print 'Testing relu_forward function:'\n",
    "print 'difference: ', rel_error(out, correct_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU layer: backward\n",
    "Now implement the backward pass for the ReLU activation function in the `relu_backward` function and test your implementation using numeric gradient checking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing relu_backward function:\n",
      "dx error:  3.27562214634e-12\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(10, 10)\n",
    "dout = np.random.randn(*x.shape)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: relu_forward(x)[0], x, dout)\n",
    "\n",
    "_, cache = relu_forward(x)\n",
    "dx = relu_backward(dout, cache)\n",
    "\n",
    "# The error should be around 1e-12\n",
    "print 'Testing relu_backward function:'\n",
    "print 'dx error: ', rel_error(dx_num, dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Sandwich\" layers\n",
    "There are some common patterns of layers that are frequently used in neural nets. For example, affine layers are frequently followed by a ReLU nonlinearity. To make these common patterns easy, we define several convenience layers in the file `cs231n/layer_utils.py`.\n",
    "\n",
    "For now take a look at the `affine_relu_forward` and `affine_relu_backward` functions, and run the following to numerically gradient check the backward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_relu_forward:\n",
      "dx error:  9.68331309455e-09\n",
      "dw error:  1.29527192233e-10\n",
      "db error:  7.82664814944e-12\n"
     ]
    }
   ],
   "source": [
    "from cs231n.layer_utils import affine_relu_forward, affine_relu_backward\n",
    "\n",
    "x = np.random.randn(2, 3, 4)\n",
    "w = np.random.randn(12, 10)\n",
    "b = np.random.randn(10)\n",
    "dout = np.random.randn(2, 10)\n",
    "\n",
    "out, cache = affine_relu_forward(x, w, b)\n",
    "dx, dw, db = affine_relu_backward(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: affine_relu_forward(x, w, b)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: affine_relu_forward(x, w, b)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: affine_relu_forward(x, w, b)[0], b, dout)\n",
    "\n",
    "print 'Testing affine_relu_forward:'\n",
    "print 'dx error: ', rel_error(dx_num, dx)\n",
    "print 'dw error: ', rel_error(dw_num, dw)\n",
    "print 'db error: ', rel_error(db_num, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss layers: Softmax and SVM\n",
    "You implemented these loss functions in the last assignment, so we'll give them to you for free here. You should still make sure you understand how they work by looking at the implementations in `cs231n/layers.py`.\n",
    "\n",
    "You can make sure that the implementations are correct by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing svm_loss:\n",
      "loss:  8.99966574748\n",
      "dx error:  3.0387355051e-09\n",
      "\n",
      "Testing softmax_loss:\n",
      "loss:  2.30255217066\n",
      "dx error:  8.95897503509e-09\n"
     ]
    }
   ],
   "source": [
    "num_classes, num_inputs = 10, 50\n",
    "x = 0.001 * np.random.randn(num_inputs, num_classes)\n",
    "y = np.random.randint(num_classes, size=num_inputs)\n",
    "\n",
    "dx_num = eval_numerical_gradient(lambda x: svm_loss(x, y)[0], x, verbose=False)\n",
    "loss, dx = svm_loss(x, y)\n",
    "\n",
    "# Test svm_loss function. Loss should be around 9 and dx error should be 1e-9\n",
    "print 'Testing svm_loss:'\n",
    "print 'loss: ', loss\n",
    "print 'dx error: ', rel_error(dx_num, dx)\n",
    "\n",
    "dx_num = eval_numerical_gradient(lambda x: softmax_loss(x, y)[0], x, verbose=False)\n",
    "loss, dx = softmax_loss(x, y)\n",
    "\n",
    "# Test softmax_loss function. Loss should be 2.3 and dx error should be 1e-8\n",
    "print '\\nTesting softmax_loss:'\n",
    "print 'loss: ', loss\n",
    "print 'dx error: ', rel_error(dx_num, dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-layer network\n",
    "In the previous assignment you implemented a two-layer neural network in a single monolithic class. Now that you have implemented modular versions of the necessary layers, you will reimplement the two layer network using these modular implementations.\n",
    "\n",
    "Open the file `cs231n/classifiers/fc_net.py` and complete the implementation of the `TwoLayerNet` class. This class will serve as a model for the other networks you will implement in this assignment, so read through it to make sure you understand the API. You can run the cell below to test your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing initialization ... \n",
      "Testing test-time forward pass ... \n",
      "Testing training loss (no regularization)\n",
      "Running numeric gradient check with reg =  0.0\n",
      "W1 relative error: 1.22e-08\n",
      "W2 relative error: 3.57e-10\n",
      "b1 relative error: 8.37e-09\n",
      "b2 relative error: 2.53e-10\n",
      "Running numeric gradient check with reg =  0.7\n",
      "W1 relative error: 2.53e-07\n",
      "W2 relative error: 1.37e-07\n",
      "b1 relative error: 1.56e-08\n",
      "b2 relative error: 9.09e-10\n"
     ]
    }
   ],
   "source": [
    "N, D, H, C = 3, 5, 50, 7\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=N)\n",
    "\n",
    "std = 1e-2\n",
    "model = TwoLayerNet(input_dim=D, hidden_dim=H, num_classes=C, weight_scale=std)\n",
    "\n",
    "print 'Testing initialization ... '\n",
    "W1_std = abs(model.params['W1'].std() - std)\n",
    "b1 = model.params['b1']\n",
    "W2_std = abs(model.params['W2'].std() - std)\n",
    "b2 = model.params['b2']\n",
    "assert W1_std < std / 10, 'First layer weights do not seem right'\n",
    "assert np.all(b1 == 0), 'First layer biases do not seem right'\n",
    "assert W2_std < std / 10, 'Second layer weights do not seem right'\n",
    "assert np.all(b2 == 0), 'Second layer biases do not seem right'\n",
    "\n",
    "print 'Testing test-time forward pass ... '\n",
    "model.params['W1'] = np.linspace(-0.7, 0.3, num=D*H).reshape(D, H)\n",
    "model.params['b1'] = np.linspace(-0.1, 0.9, num=H)\n",
    "model.params['W2'] = np.linspace(-0.3, 0.4, num=H*C).reshape(H, C)\n",
    "model.params['b2'] = np.linspace(-0.9, 0.1, num=C)\n",
    "X = np.linspace(-5.5, 4.5, num=N*D).reshape(D, N).T\n",
    "scores = model.loss(X)\n",
    "correct_scores = np.asarray(\n",
    "  [[11.53165108,  12.2917344,   13.05181771,  13.81190102,  14.57198434, 15.33206765,  16.09215096],\n",
    "   [12.05769098,  12.74614105,  13.43459113,  14.1230412,   14.81149128, 15.49994135,  16.18839143],\n",
    "   [12.58373087,  13.20054771,  13.81736455,  14.43418138,  15.05099822, 15.66781506,  16.2846319 ]])\n",
    "scores_diff = np.abs(scores - correct_scores).sum()\n",
    "assert scores_diff < 1e-6, 'Problem with test-time forward pass'\n",
    "\n",
    "print 'Testing training loss (no regularization)'\n",
    "y = np.asarray([0, 5, 1])\n",
    "loss, grads = model.loss(X, y)\n",
    "correct_loss = 3.4702243556\n",
    "assert abs(loss - correct_loss) < 1e-10, 'Problem with training-time loss'\n",
    "\n",
    "model.reg = 1.0\n",
    "loss, grads = model.loss(X, y)\n",
    "correct_loss = 26.5948426952\n",
    "assert abs(loss - correct_loss) < 1e-10, 'Problem with regularization loss'\n",
    "\n",
    "for reg in [0.0, 0.7]:\n",
    "  print 'Running numeric gradient check with reg = ', reg\n",
    "  model.reg = reg\n",
    "  loss, grads = model.loss(X, y)\n",
    "\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False)\n",
    "    print '%s relative error: %.2e' % (name, rel_error(grad_num, grads[name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solver\n",
    "In the previous assignment, the logic for training models was coupled to the models themselves. Following a more modular design, for this assignment we have split the logic for training models into a separate class.\n",
    "\n",
    "Open the file `cs231n/solver.py` and read through it to familiarize yourself with the API. After doing so, use a `Solver` instance to train a `TwoLayerNet` that achieves at least `50%` accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "solver = None\n",
    "#data = {'X_train': X_train, 'X_val': X_val, 'y_train': y_train, 'y_val': y_val}\n",
    "input_dim = 3*32*32\n",
    "hidden_dim = 300\n",
    "num_classes = 10\n",
    "num_iters = 15\n",
    "results = {}\n",
    "\n",
    "for it in xrange(num_iters):\n",
    "    reg = np.random.uniform(0.1, 1, 1)[0]\n",
    "    lr = np.random.uniform(0.0006, 0.0008, 1)[0]\n",
    "    #reg = np.random.uniform(1e-2, 1e-1, 1)[0]\n",
    "    #lr = np.random.uniform(1e-4, 1e-3, 1)[0]\n",
    "    model = TwoLayerNet(input_dim, hidden_dim, num_classes, weight_scale=1e-3, reg=reg)\n",
    "    solver = Solver(model, data, update_rule='sgd', optim_config={'learning_rate': lr}, \n",
    "                lr_decay=0.95, num_epochs = 1, batch_size=100, print_every=100, verbose=False)\n",
    "    solver.train()\n",
    "    results[(lr, reg)] = (solver.train_acc_history[-1], solver.val_acc_history[-1])\n",
    "    #print \"lr: %f.5, reg: %f.5, train_acc: %f.5, val_acc: %f.5\"%(lr, reg, solver.train_acc_history[-1], \n",
    "                                                                 #solver.val_acc_history[-1])\n",
    "##############################################################################\n",
    "# TODO: Use a Solver instance to train a TwoLayerNet that achieves at least  #\n",
    "# 50% accuracy on the validation set.                                        #\n",
    "##############################################################################\n",
    "pass\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0.00062237404798265515, 0.53019854596163374), (0.44, 0.46999999999999997)),\n",
       " ((0.00067785579446320876, 0.38918331121349525),\n",
       "  (0.46500000000000002, 0.46200000000000002)),\n",
       " ((0.00072973141638048148, 0.97345652723797482), (0.442, 0.45800000000000002)),\n",
       " ((0.00078754086873108575, 0.41830765194911634),\n",
       "  (0.42699999999999999, 0.45800000000000002)),\n",
       " ((0.00074038318272684782, 0.33232129473465033),\n",
       "  (0.42599999999999999, 0.45500000000000002)),\n",
       " ((0.00077194375527809948, 0.97590798542273405),\n",
       "  (0.46500000000000002, 0.45400000000000001)),\n",
       " ((0.00066585793960689853, 0.47267590031908213), (0.441, 0.45200000000000001)),\n",
       " ((0.00074432222601766894, 0.79088164195602351),\n",
       "  (0.46899999999999997, 0.45100000000000001)),\n",
       " ((0.00079899143915713013, 0.71681153714939183), (0.434, 0.45100000000000001)),\n",
       " ((0.00065131358855496859, 0.37847227344188206),\n",
       "  (0.46999999999999997, 0.45000000000000001))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x = {'a': (1,6), 'b': (2,4)}\n",
    "sorted(results.items(), key=lambda x: x[1][1], reverse=True)[:10]\n",
    "#0.00062237404798265515, 0.53019854596163374"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3cAAALXCAYAAAAuWLlMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIiIiCSA/w+cFKQleWyBPAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f71a217ab10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to visualize training loss and train / val accuracy\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(solver.train_acc_history, '-o', label='train')\n",
    "plt.plot(solver.val_acc_history, '-o', label='val')\n",
    "plt.plot([0.5] * len(solver.val_acc_history), 'k--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.gcf().set_size_inches(15, 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "a=[1,2,3]\n",
    "b=4\n",
    "c=a+[b]\n",
    "print c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer network\n",
    "Next you will implement a fully-connected network with an arbitrary number of hidden layers.\n",
    "\n",
    "Read through the `FullyConnectedNet` class in the file `cs231n/classifiers/fc_net.py`.\n",
    "\n",
    "Implement the initialization, the forward pass, and the backward pass. For the moment don't worry about implementing dropout or batch normalization; we will add those features soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial loss and gradient check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, run the following to check the initial loss and to gradient check the network both with and without regularization. Do the initial losses seem reasonable?\n",
    "\n",
    "For gradient checking, you should expect to see errors around 1e-6 or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N, D, H1, H2, C = 2, 15, 20, 30, 10\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=(N,))\n",
    "\n",
    "for reg in [0, 3.14]:\n",
    "  print 'Running check with reg = ', reg\n",
    "  model = FullyConnectedNet([H1, H2], input_dim=D, num_classes=C,\n",
    "                            reg=reg, weight_scale=5e-2, dtype=np.float64)\n",
    "\n",
    "  loss, grads = model.loss(X, y)\n",
    "  print 'Initial loss: ', loss\n",
    "\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False, h=1e-5)\n",
    "    print '%s relative error: %.2e' % (name, rel_error(grad_num, grads[name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another sanity check, make sure you can overfit a small dataset of 50 images. First we will try a three-layer network with 100 units in each hidden layer. You will need to tweak the learning rate and initialization scale, but you should be able to overfit and achieve 100% training accuracy within 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: Use a three-layer Net to overfit 50 training examples.\n",
    "\n",
    "num_train = 50\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "weight_scale = 1e-2\n",
    "learning_rate = 1e-4\n",
    "model = FullyConnectedNet([100, 100],\n",
    "              weight_scale=weight_scale, dtype=np.float64)\n",
    "solver = Solver(model, small_data,\n",
    "                print_every=10, num_epochs=20, batch_size=25,\n",
    "                update_rule='sgd',\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate,\n",
    "                }\n",
    "         )\n",
    "solver.train()\n",
    "\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.title('Training loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to use a five-layer network with 100 units on each layer to overfit 50 training examples. Again you will have to adjust the learning rate and weight initialization, but you should be able to achieve 100% training accuracy within 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Use a five-layer Net to overfit 50 training examples.\n",
    "\n",
    "num_train = 50\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "learning_rate = 1e-3\n",
    "weight_scale = 1e-5\n",
    "model = FullyConnectedNet([100, 100, 100, 100],\n",
    "                weight_scale=weight_scale, dtype=np.float64)\n",
    "solver = Solver(model, small_data,\n",
    "                print_every=10, num_epochs=20, batch_size=25,\n",
    "                update_rule='sgd',\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate,\n",
    "                }\n",
    "         )\n",
    "solver.train()\n",
    "\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.title('Training loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inline question: \n",
    "Did you notice anything about the comparative difficulty of training the three-layer net vs training the five layer net?\n",
    "\n",
    "# Answer:\n",
    "[FILL THIS IN]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update rules\n",
    "So far we have used vanilla stochastic gradient descent (SGD) as our update rule. More sophisticated update rules can make it easier to train deep networks. We will implement a few of the most commonly used update rules and compare them to vanilla SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD+Momentum\n",
    "Stochastic gradient descent with momentum is a widely used update rule that tends to make deep networks converge faster than vanilla stochstic gradient descent.\n",
    "\n",
    "Open the file `cs231n/optim.py` and read the documentation at the top of the file to make sure you understand the API. Implement the SGD+momentum update rule in the function `sgd_momentum` and run the following to check your implementation. You should see errors less than 1e-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cs231n.optim import sgd_momentum\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "v = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-3, 'velocity': v}\n",
    "next_w, _ = sgd_momentum(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [ 0.1406,      0.20738947,  0.27417895,  0.34096842,  0.40775789],\n",
    "  [ 0.47454737,  0.54133684,  0.60812632,  0.67491579,  0.74170526],\n",
    "  [ 0.80849474,  0.87528421,  0.94207368,  1.00886316,  1.07565263],\n",
    "  [ 1.14244211,  1.20923158,  1.27602105,  1.34281053,  1.4096    ]])\n",
    "expected_velocity = np.asarray([\n",
    "  [ 0.5406,      0.55475789,  0.56891579, 0.58307368,  0.59723158],\n",
    "  [ 0.61138947,  0.62554737,  0.63970526,  0.65386316,  0.66802105],\n",
    "  [ 0.68217895,  0.69633684,  0.71049474,  0.72465263,  0.73881053],\n",
    "  [ 0.75296842,  0.76712632,  0.78128421,  0.79544211,  0.8096    ]])\n",
    "\n",
    "print 'next_w error: ', rel_error(next_w, expected_next_w)\n",
    "print 'velocity error: ', rel_error(expected_velocity, config['velocity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have done so, run the following to train a six-layer network with both SGD and SGD+momentum. You should see the SGD+momentum update rule converge faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_train = 4000\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "solvers = {}\n",
    "\n",
    "for update_rule in ['sgd', 'sgd_momentum']:\n",
    "  print 'running with ', update_rule\n",
    "  model = FullyConnectedNet([100, 100, 100, 100, 100], weight_scale=5e-2)\n",
    "\n",
    "  solver = Solver(model, small_data,\n",
    "                  num_epochs=5, batch_size=100,\n",
    "                  update_rule=update_rule,\n",
    "                  optim_config={\n",
    "                    'learning_rate': 1e-2,\n",
    "                  },\n",
    "                  verbose=True)\n",
    "  solvers[update_rule] = solver\n",
    "  solver.train()\n",
    "  print\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "for update_rule, solver in solvers.iteritems():\n",
    "  plt.subplot(3, 1, 1)\n",
    "  plt.plot(solver.loss_history, 'o', label=update_rule)\n",
    "  \n",
    "  plt.subplot(3, 1, 2)\n",
    "  plt.plot(solver.train_acc_history, '-o', label=update_rule)\n",
    "\n",
    "  plt.subplot(3, 1, 3)\n",
    "  plt.plot(solver.val_acc_history, '-o', label=update_rule)\n",
    "  \n",
    "for i in [1, 2, 3]:\n",
    "  plt.subplot(3, 1, i)\n",
    "  plt.legend(loc='upper center', ncol=4)\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSProp and Adam\n",
    "RMSProp [1] and Adam [2] are update rules that set per-parameter learning rates by using a running average of the second moments of gradients.\n",
    "\n",
    "In the file `cs231n/optim.py`, implement the RMSProp update rule in the `rmsprop` function and implement the Adam update rule in the `adam` function, and check your implementations using the tests below.\n",
    "\n",
    "[1] Tijmen Tieleman and Geoffrey Hinton. \"Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude.\" COURSERA: Neural Networks for Machine Learning 4 (2012).\n",
    "\n",
    "[2] Diederik Kingma and Jimmy Ba, \"Adam: A Method for Stochastic Optimization\", ICLR 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test RMSProp implementation; you should see errors less than 1e-7\n",
    "from cs231n.optim import rmsprop\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "cache = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-2, 'cache': cache}\n",
    "next_w, _ = rmsprop(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [-0.39223849, -0.34037513, -0.28849239, -0.23659121, -0.18467247],\n",
    "  [-0.132737,   -0.08078555, -0.02881884,  0.02316247,  0.07515774],\n",
    "  [ 0.12716641,  0.17918792,  0.23122175,  0.28326742,  0.33532447],\n",
    "  [ 0.38739248,  0.43947102,  0.49155973,  0.54365823,  0.59576619]])\n",
    "expected_cache = np.asarray([\n",
    "  [ 0.5976,      0.6126277,   0.6277108,   0.64284931,  0.65804321],\n",
    "  [ 0.67329252,  0.68859723,  0.70395734,  0.71937285,  0.73484377],\n",
    "  [ 0.75037008,  0.7659518,   0.78158892,  0.79728144,  0.81302936],\n",
    "  [ 0.82883269,  0.84469141,  0.86060554,  0.87657507,  0.8926    ]])\n",
    "\n",
    "print 'next_w error: ', rel_error(expected_next_w, next_w)\n",
    "print 'cache error: ', rel_error(expected_cache, config['cache'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test Adam implementation; you should see errors around 1e-7 or less\n",
    "from cs231n.optim import adam\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "m = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "v = np.linspace(0.7, 0.5, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-2, 'm': m, 'v': v, 't': 5}\n",
    "next_w, _ = adam(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [-0.40094747, -0.34836187, -0.29577703, -0.24319299, -0.19060977],\n",
    "  [-0.1380274,  -0.08544591, -0.03286534,  0.01971428,  0.0722929],\n",
    "  [ 0.1248705,   0.17744702,  0.23002243,  0.28259667,  0.33516969],\n",
    "  [ 0.38774145,  0.44031188,  0.49288093,  0.54544852,  0.59801459]])\n",
    "expected_v = np.asarray([\n",
    "  [ 0.69966,     0.68908382,  0.67851319,  0.66794809,  0.65738853,],\n",
    "  [ 0.64683452,  0.63628604,  0.6257431,   0.61520571,  0.60467385,],\n",
    "  [ 0.59414753,  0.58362676,  0.57311152,  0.56260183,  0.55209767,],\n",
    "  [ 0.54159906,  0.53110598,  0.52061845,  0.51013645,  0.49966,   ]])\n",
    "expected_m = np.asarray([\n",
    "  [ 0.48,        0.49947368,  0.51894737,  0.53842105,  0.55789474],\n",
    "  [ 0.57736842,  0.59684211,  0.61631579,  0.63578947,  0.65526316],\n",
    "  [ 0.67473684,  0.69421053,  0.71368421,  0.73315789,  0.75263158],\n",
    "  [ 0.77210526,  0.79157895,  0.81105263,  0.83052632,  0.85      ]])\n",
    "\n",
    "print 'next_w error: ', rel_error(expected_next_w, next_w)\n",
    "print 'v error: ', rel_error(expected_v, config['v'])\n",
    "print 'm error: ', rel_error(expected_m, config['m'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have debugged your RMSProp and Adam implementations, run the following to train a pair of deep networks using these new update rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rates = {'rmsprop': 1e-4, 'adam': 1e-3}\n",
    "for update_rule in ['adam', 'rmsprop']:\n",
    "  print 'running with ', update_rule\n",
    "  model = FullyConnectedNet([100, 100, 100, 100, 100], weight_scale=5e-2)\n",
    "\n",
    "  solver = Solver(model, small_data,\n",
    "                  num_epochs=5, batch_size=100,\n",
    "                  update_rule=update_rule,\n",
    "                  optim_config={\n",
    "                    'learning_rate': learning_rates[update_rule]\n",
    "                  },\n",
    "                  verbose=True)\n",
    "  solvers[update_rule] = solver\n",
    "  solver.train()\n",
    "  print\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "for update_rule, solver in solvers.iteritems():\n",
    "  plt.subplot(3, 1, 1)\n",
    "  plt.plot(solver.loss_history, 'o', label=update_rule)\n",
    "  \n",
    "  plt.subplot(3, 1, 2)\n",
    "  plt.plot(solver.train_acc_history, '-o', label=update_rule)\n",
    "\n",
    "  plt.subplot(3, 1, 3)\n",
    "  plt.plot(solver.val_acc_history, '-o', label=update_rule)\n",
    "  \n",
    "for i in [1, 2, 3]:\n",
    "  plt.subplot(3, 1, i)\n",
    "  plt.legend(loc='upper center', ncol=4)\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a good model!\n",
    "Train the best fully-connected model that you can on CIFAR-10, storing your best model in the `best_model` variable. We require you to get at least 50% accuracy on the validation set using a fully-connected net.\n",
    "\n",
    "If you are careful it should be possible to get accuracies above 55%, but we don't require it for this part and won't assign extra credit for doing so. Later in the assignment we will ask you to train the best convolutional network that you can on CIFAR-10, and we would prefer that you spend your effort working on convolutional nets rather than fully-connected nets.\n",
    "\n",
    "You might find it useful to complete the `BatchNormalization.ipynb` and `Dropout.ipynb` notebooks before completing this part, since those techniques can help you train powerful models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_model = None\n",
    "################################################################################\n",
    "# TODO: Train the best FullyConnectedNet that you can on CIFAR-10. You might   #\n",
    "# batch normalization and dropout useful. Store your best model in the         #\n",
    "# best_model variable.                                                         #\n",
    "################################################################################\n",
    "pass\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test you model\n",
    "Run your best model on the validation and test sets. You should achieve above 50% accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(best_model.loss(X_test), axis=1)\n",
    "y_val_pred = np.argmax(best_model.loss(X_val), axis=1)\n",
    "print 'Validation set accuracy: ', (y_val_pred == y_val).mean()\n",
    "print 'Test set accuracy: ', (y_test_pred == y_test).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
